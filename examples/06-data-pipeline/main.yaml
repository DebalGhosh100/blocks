blocks:
  - name: "Setup Pipeline Environment"
    description: "Create directories for data pipeline stages"
    run: |
      mkdir -p ${pipeline.paths.raw_data}
      mkdir -p ${pipeline.paths.processed_data}
      mkdir -p ${pipeline.paths.output}
      mkdir -p ./logs
      echo "Pipeline environment ready!"

  - name: "Fetch Raw Data"
    description: "Download or generate raw data for processing"
    run: |
      echo "Fetching raw data from sources..."
      echo "Dataset 1: Weather data" > ${pipeline.paths.raw_data}/weather.csv
      for i in {1..100}; do
        echo "2024-01-$i,25.$i,60.$i" >> ${pipeline.paths.raw_data}/weather.csv
      done
      
      echo "Dataset 2: Sales data" > ${pipeline.paths.raw_data}/sales.csv
      for i in {1..100}; do
        echo "2024-01-$i,product_$i,$((1000 + i))" >> ${pipeline.paths.raw_data}/sales.csv
      done
      
      echo "Dataset 3: User activity" > ${pipeline.paths.raw_data}/activity.csv
      for i in {1..100}; do
        echo "user_$i,action_$i,2024-01-$i" >> ${pipeline.paths.raw_data}/activity.csv
      done
      
      echo "Raw data fetched successfully!"
      ls -lh ${pipeline.paths.raw_data}

  - parallel:
      - name: "Process Weather Data"
        description: "Clean and transform weather data"
        run: |
          echo "Processing weather data..."
          input="${pipeline.paths.raw_data}/weather.csv"
          output="${pipeline.paths.processed_data}/weather_processed.csv"
          
          # Simulate processing with validation
          echo "date,temperature,humidity" > $output
          tail -n +2 $input | while IFS=',' read date temp humid; do
            # Simple validation: remove invalid entries
            if [ ! -z "$date" ] && [ ! -z "$temp" ]; then
              echo "$date,$temp,$humid" >> $output
            fi
          done
          
          record_count=$(wc -l < $output)
          echo "Weather data processed: $record_count records"
          echo "Weather processing complete!" > ./logs/weather_process.log

      - name: "Process Sales Data"
        description: "Clean and transform sales data"
        run: |
          echo "Processing sales data..."
          input="${pipeline.paths.raw_data}/sales.csv"
          output="${pipeline.paths.processed_data}/sales_processed.csv"
          
          # Simulate processing with aggregation
          echo "date,product,amount" > $output
          tail -n +2 $input | while IFS=',' read date product amount; do
            if [ ! -z "$date" ] && [ $amount -gt 0 ] 2>/dev/null; then
              echo "$date,$product,$amount" >> $output
            fi
          done
          
          record_count=$(wc -l < $output)
          echo "Sales data processed: $record_count records"
          echo "Sales processing complete!" > ./logs/sales_process.log

      - name: "Process Activity Data"
        description: "Clean and transform user activity data"
        run: |
          echo "Processing activity data..."
          input="${pipeline.paths.raw_data}/activity.csv"
          output="${pipeline.paths.processed_data}/activity_processed.csv"
          
          # Simulate processing with filtering
          echo "user,action,date" > $output
          tail -n +2 $input | while IFS=',' read user action date; do
            if [ ! -z "$user" ] && [ ! -z "$action" ]; then
              echo "$user,$action,$date" >> $output
            fi
          done
          
          record_count=$(wc -l < $output)
          echo "Activity data processed: $record_count records"
          echo "Activity processing complete!" > ./logs/activity_process.log

  - name: "Verify Processing Stage"
    description: "Verify all data processing completed successfully"
    run: |
      echo "=========================================="
      echo "   PROCESSING STAGE VERIFICATION"
      echo "=========================================="
      echo ""
      echo "Processed files:"
      ls -lh ${pipeline.paths.processed_data}
      echo ""
      echo "Processing logs:"
      cat ./logs/weather_process.log
      cat ./logs/sales_process.log
      cat ./logs/activity_process.log
      echo ""
      echo "All data processing complete!"

  - parallel:
      - name: "Generate Weather Report"
        description: "Create analysis report for weather data"
        run: |
          echo "Generating weather report..."
          input="${pipeline.paths.processed_data}/weather_processed.csv"
          output="${pipeline.paths.output}/weather_report.txt"
          
          echo "=== Weather Data Analysis Report ===" > $output
          echo "Generated: $(date)" >> $output
          echo "" >> $output
          
          record_count=$(tail -n +2 $input | wc -l)
          echo "Total Records: $record_count" >> $output
          
          avg_temp=$(tail -n +2 $input | cut -d',' -f2 | awk '{sum+=$1} END {print sum/NR}')
          echo "Average Temperature: $avg_temp°C" >> $output
          
          echo "" >> $output
          echo "Sample Records (first 5):" >> $output
          head -n 6 $input | tail -n 5 >> $output
          
          echo "Weather report generated!"

      - name: "Generate Sales Report"
        description: "Create analysis report for sales data"
        run: |
          echo "Generating sales report..."
          input="${pipeline.paths.processed_data}/sales_processed.csv"
          output="${pipeline.paths.output}/sales_report.txt"
          
          echo "=== Sales Data Analysis Report ===" > $output
          echo "Generated: $(date)" >> $output
          echo "" >> $output
          
          record_count=$(tail -n +2 $input | wc -l)
          echo "Total Transactions: $record_count" >> $output
          
          total_sales=$(tail -n +2 $input | cut -d',' -f3 | awk '{sum+=$1} END {print sum}')
          echo "Total Sales Amount: \$$total_sales" >> $output
          
          avg_sale=$(tail -n +2 $input | cut -d',' -f3 | awk '{sum+=$1} END {print sum/NR}')
          echo "Average Transaction: \$$avg_sale" >> $output
          
          echo "" >> $output
          echo "Sample Records (first 5):" >> $output
          head -n 6 $input | tail -n 5 >> $output
          
          echo "Sales report generated!"

      - name: "Generate Activity Report"
        description: "Create analysis report for activity data"
        run: |
          echo "Generating activity report..."
          input="${pipeline.paths.processed_data}/activity_processed.csv"
          output="${pipeline.paths.output}/activity_report.txt"
          
          echo "=== User Activity Analysis Report ===" > $output
          echo "Generated: $(date)" >> $output
          echo "" >> $output
          
          record_count=$(tail -n +2 $input | wc -l)
          echo "Total Activities: $record_count" >> $output
          
          unique_users=$(tail -n +2 $input | cut -d',' -f1 | sort -u | wc -l)
          echo "Unique Users: $unique_users" >> $output
          
          echo "" >> $output
          echo "Sample Records (first 5):" >> $output
          head -n 6 $input | tail -n 5 >> $output
          
          echo "Activity report generated!"

  - name: "Generate Master Report"
    description: "Combine all reports into master summary"
    run: |
      echo "Generating master report..."
      master="${pipeline.paths.output}/master_report.txt"
      
      echo "╔════════════════════════════════════════════════╗" > $master
      echo "║     DATA PIPELINE MASTER REPORT                ║" >> $master
      echo "╚════════════════════════════════════════════════╝" >> $master
      echo "" >> $master
      echo "Pipeline: ${pipeline.name}" >> $master
      echo "Version: ${pipeline.version}" >> $master
      echo "Execution Date: $(date)" >> $master
      echo "" >> $master
      echo "──────────────────────────────────────────────────" >> $master
      echo "" >> $master
      
      cat ${pipeline.paths.output}/weather_report.txt >> $master
      echo "" >> $master
      echo "──────────────────────────────────────────────────" >> $master
      echo "" >> $master
      
      cat ${pipeline.paths.output}/sales_report.txt >> $master
      echo "" >> $master
      echo "──────────────────────────────────────────────────" >> $master
      echo "" >> $master
      
      cat ${pipeline.paths.output}/activity_report.txt >> $master
      echo "" >> $master
      echo "══════════════════════════════════════════════════" >> $master
      echo "Pipeline execution completed successfully!" >> $master
      
      echo "Master report generated!"

  - name: "Display Results"
    description: "Show the master report"
    run: |
      echo ""
      cat ${pipeline.paths.output}/master_report.txt
      echo ""

  - name: "Pipeline Statistics"
    description: "Show pipeline execution statistics"
    run: |
      echo "=========================================="
      echo "     PIPELINE EXECUTION STATISTICS"
      echo "=========================================="
      echo ""
      echo "Input Files:"
      ls -lh ${pipeline.paths.raw_data}
      echo ""
      echo "Processed Files:"
      ls -lh ${pipeline.paths.processed_data}
      echo ""
      echo "Output Reports:"
      ls -lh ${pipeline.paths.output}
      echo ""
      echo "Pipeline complete!"

  - name: "Cleanup"
    description: "Clean up temporary files (optional)"
    run: |
      echo "Keeping all pipeline outputs for review."
      echo "To clean up, run: rm -rf ${pipeline.paths.raw_data} ${pipeline.paths.processed_data} ${pipeline.paths.output}"
